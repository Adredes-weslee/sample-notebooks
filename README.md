# Predictive Maintenance — XGBoost + SHAP (Notebook + Streamlit)

End-to-end notebook that:
- Trains an XGBoost classifier on an Industrial IoT fault dataset (with offline fallbacks).
- Performs V&V (PR-AUC, ROC-AUC, confusion matrix, calibration/ECE, threshold tuning).
- Generates global and local SHAP explanations.
- Builds a Streamlit diagnostic app with sliders and a live SHAP waterfall.
- Exports artifacts (metrics, plots, model card, app).

## Quickstart (Windows + VS Code)

1) Create and activate a virtual environment
```powershell
py -m venv .venv
.\.venv\Scripts\activate
pip install --upgrade pip
```

2) Install dependencies (either run the notebook “Install Packages” cell, or pip directly)
```powershell
pip install pandas numpy scikit-learn xgboost shap matplotlib seaborn streamlit opendatasets
```

3) Provide data (any one works)
- Preferred: place your CSV at data/iot_faults.csv. If present, the pipeline skips any Kaggle download.
- Reuse: any CSV previously downloaded under data/kaggle/**.csv will be reused automatically.
- Mirror fallback: public sample CSV (used only if above are unavailable).
- Last resort: small synthetic dataset autogenerated in-notebook.

Note on column names: the notebook normalizes headers to TitleCase with underscores (e.g., “Vibration (mm/s)” → “Vibration_(Mm/S)”, “Fault Label” → “Fault_Label”). Labels are unified to Fault.

4) Run the notebook
- Execute cells top to bottom. This produces:
  - models/xgb.pkl, models/scaler.pkl
  - models/features_meta.json, models/shap_bg.npy
  - artifacts/metrics.json, artifacts/ece.json, artifacts/threshold.json
  - artifacts/plots/*.png
  - artifacts/vnv_report.md, artifacts/model_card.md

5) Launch the Streamlit app
```powershell
python -m streamlit run app/app.py --server.address localhost --server.port 8501
```
Then open http://localhost:8501.

## App usage
- Adjust key sensor sliders on the left and choose a decision threshold.
- Click “Predict Status” to compute probability and show a SHAP waterfall for that setting.
- “Download V&V Report” saves artifacts/vnv_report.md.

## Data handling
- Local file: data/iot_faults.csv takes precedence (Kaggle download is skipped).
- Kaggle reuse: if a CSV exists in data/kaggle/, it is reused without re-downloading.
- Offline: auto-detected; Kaggle is skipped when offline.

## Troubleshooting

- Flat/zero-ish SHAP bars or cluttered x-axis ticks:
  - By default sliders start at feature means; if the background is also near the mean, f(x) ≈ E[f(X)] and SHAP ≈ 0. Move sliders away from means.
  - Ensure models/shap_bg.npy exists (generated in preprocessing). The app prefers this background.
  - The app formats the x-axis to compact values; if you still see clutter, zoom or reduce displayed features.

- “Fault_Label” shows up as a feature:
  - The preprocessing removes label-like columns from features. If you trained before this fix, delete models/features_meta.json and retrain (run preprocessing + training cells).

- Kaggle auth/permission issues:
  - Provide a local CSV at data/iot_faults.csv or set OFFLINE=True in the bootstrap cell. The code will skip Kaggle and use mirror/synthetic fallbacks.

## Outputs
- Model: models/xgb.pkl
- Scaler + meta: models/scaler.pkl, models/features_meta.json
- SHAP background: models/shap_bg.npy
- Metrics & plots: artifacts/metrics.json, artifacts/plots/*
- Calibration & threshold: artifacts/ece.json, artifacts/threshold.json
- Reports: artifacts/vnv_report.md, artifacts/model_card.md

## Notes
- Random seeds fixed (SEED=42) for reproducibility.
- XGBoost uses scale_pos_weight for class imbalance.
- SHAP uses TreeExplainer with interventional perturbation and probability output.